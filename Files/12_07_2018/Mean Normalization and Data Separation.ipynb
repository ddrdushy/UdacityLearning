{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4222 4153 1363 ..., 1794 1122 4329]\n",
      " [2960 4885   49 ..., 3435 1008  479]\n",
      " [4931 3298 1283 ..., 1212 1509  536]\n",
      " ..., \n",
      " [4382 2800 1469 ..., 1706 1481 2114]\n",
      " [3897 3820  927 ..., 4346 2423 2951]\n",
      " [ 515  553 3214 ..., 4777 3695    7]]\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001,size=(1000,20))\n",
    "\n",
    "# print the shape of X\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = X.mean(axis=0)\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2568.225  2539.403  2493.194  2514.301  2533.095  2541.651  2564.767\n",
      "  2537.747  2599.536  2489.54   2470.046  2510.175  2500.214  2578.642\n",
      "  2557.28   2527.465  2576.928  2461.544  2463.59   2549.254]\n",
      "[ 1429.46066626  1452.18287712  1461.17139664  1445.01442152  1415.95485662\n",
      "  1441.57111972  1454.92903219  1397.15204004  1462.26941864  1456.96588581\n",
      "  1472.97235544  1425.68773733  1461.31747687  1455.26301672  1450.99242851\n",
      "  1493.77325815  1475.34858146  1441.71864941  1427.45491344  1421.54948542]\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X-ave_cols)/std_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.15692235  1.11115275 -0.77348489 ..., -0.46301961 -0.93984755\n",
      "   1.25197611]\n",
      " [ 0.2740719   1.6152215  -1.67276338 ...,  0.67520525 -1.01970997\n",
      "  -1.45633622]\n",
      " [ 1.65291362  0.52238393 -0.82823548 ..., -0.86670447 -0.66873566\n",
      "  -1.41623913]\n",
      " ..., \n",
      " [ 1.26885268  0.17945192 -0.70094036 ..., -0.52405787 -0.68835099\n",
      "  -0.3061828 ]\n",
      " [ 0.92956388  0.88184279 -1.07187562 ...,  1.30708998 -0.02843522\n",
      "   0.28261134]\n",
      " [-1.43636341 -1.36787386  0.49330695 ...,  1.60603874  0.86266122\n",
      "  -1.78836827]]\n",
      "-1.76192394008e-16\n",
      "-1.76192394008e-16\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(X_norm)\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(X_norm.mean(axis=0).min(axis=0))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(X_norm.mean(axis=0).min(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[206 798 703 562 313 304 936 484 783 104 173 801 600 752   8 809 489 211\n",
      " 370  40 499 648 188 247 439 663 180 971 990 336 352  32 975 825  44 535\n",
      " 174 636 755 705 467 981 602 284 172 814 579 493 457 556 440 430 788 119\n",
      " 818 516 838 324 305 926 615 185 931 414 582 893 586 606 799 946 747 144\n",
      " 341 107 943 265 358 281 460 248  61  97 258 343 639 877 744 710 696 665\n",
      " 717 182 689 496  19 782 157 348  27  53 997 634 154 552 220 302 836 517\n",
      " 408 833 177 622 858 789 332 596 593 960 243  37 840 892 631 653 441 879\n",
      " 774 954 570 567 952 860 682 957 355 565 687 816 264 779 557 934 534 966\n",
      " 384 554 670 213 168 314 401 310 807 290 340 768 203 514 259 813 181 994\n",
      " 764 146  29 597 649 431 945 624 411 702 519 580 178 453  55 745  50 272\n",
      " 192 700 388 359 283 743 842  46  25   5 413 539  17 518 847 111 335 191\n",
      " 325 929 463 784 964 619 832  22 620 193 856 307  76 486 233 360 426 140\n",
      " 465  15 886 548 464 365 389 541 231 459 127 369  13 511 739 986 817 381\n",
      " 215 450 806 894 255  77 544 321  48 475 685 105 555 402 244 560 561 694\n",
      " 163 853 824 638  21 528 123 333  98 996  90 501 306 205 980 905 184 948\n",
      "  23 907  24 230 266 254 922 641  18 488  83 497   1  86 722 394 142 576\n",
      " 330 686 852  80 354 844 721 947 406 380  99 530  96  30  68 735 753 197\n",
      " 547 896 791 750 569 245 738 235 398 317 462 187 916  92 723 982 271 800\n",
      " 504 728 226 989 550 279 318 692 658 898 536 849 889 568 811 150 202 915\n",
      " 851  59 260 147  49 269 654 763 900 246 225 740 309 520 617 222 485 671\n",
      "   9 647 224 659 729 899 574 262 315 917 339 156 204  43 985 667 379 758\n",
      " 776 250 100 468 385 762  89  42 563 827 846 822 495 564 681 167 200 608\n",
      " 958 419 538 937 553 234 500 473 770 812 885 713 432 870  60 718 344 803\n",
      " 165 421  69 640 523 409 897 773  94 950 212 765 392 126 549 716 912 153\n",
      "  45 727 478 196 884 267 268 449 285 295 588 895 263 134 969 424 276 328\n",
      " 368 451 124 458 130 695 881 674  72 183 510 238   3  11 785 400 447  95\n",
      " 629 540 487 780 227 635 446   0 503 236 278 988 273 361 974  91  74 448\n",
      " 993 166 129 935 933  16 712 498 508 415  78  65 437 219 821  73 876 578\n",
      " 319 767 151 524 967 741 808 792 864 433 112 724 195 399 766 795 652 715\n",
      " 837 621 410 704 199 601 890 590 338 662 346 607  57 599 614 923  67 676\n",
      " 618 280 984 507 880 737 903 944 137 275 481 425 949 604 605 176 483 909\n",
      " 207 455  28 532 308 456 581 610 656 286 760 102 794 375 257 515 289 434\n",
      " 331 287  88 445 804 223 778 845 970 418 261 684 805 609 118  85 603  82\n",
      " 872 888 855  38 874 796  58 863 299 919 976 925 977 668 502 690 525 706\n",
      " 742 436 959 646 883 672 164 873 632 109 911 412 786 141 345  87 587 210\n",
      " 292 951 995 404 736 697 828 428 693 133 673 420 910 834 921 179 378 675\n",
      " 218 240 113 650 751 194 117 363 559 543 961 956 566 857 470 572 810 469\n",
      " 688 316 771 136 490 442 159 820  52 108 999 367  62 904  93 169 480 298\n",
      " 664 277 850 171 391 868 953 666 901 819 395 452 777 300 422 679 301 253\n",
      " 435 491 376 972 573 312 209 680 749 132 869 466 138 732 859 623  31 983\n",
      " 228 928 734  34 726 595 998 545 383 297 143 256 733 293 930 327 471 714\n",
      " 217 942 377 927 626 865 251 772 214 709 115 542 252 405 116 887 661 759\n",
      " 698 612 598 347 356 120 854 522 918 875 829 866 731 474 103   7 669 831\n",
      " 616 158 155  84 720 643 979 655 823 472 509  79 296 152  12 407  63 148\n",
      " 914 364 841 242 992 149 906 707 291 660 711 492 932 334 416 208 585 513\n",
      " 303 282 882 537 373 746 125 558 797 216  71 423 754 529 955 382 397 756\n",
      " 201 891 628 374 106 965 924 229 326 627  54 633 644 987 657 963 591 968\n",
      " 274  41 775 337 790 683 973  64 527 802 372 357 611   2 322 198 938 551\n",
      " 862 145 190 454 479 444 366 962 438 748  66 577  56 583  26 691 329 902\n",
      " 645 625  14 232 351 839 642 526 835 878 362 393 584 128 848 920 427 387\n",
      " 241 512  39 592 320 630 575 991 135   6 546  36 533 941 781 830  10 867\n",
      " 677 761 719 342 349 871 651 122 114 161 531 978 939 294  75 270 730 443\n",
      " 371 482 477 429 170 249 160 793 826 288 417 594 637 162 139 589 861 350\n",
      " 189 678 843  20  33 769 701 237 461  81   4 175 506 311 521 353  70 110\n",
      " 908 386 239 725 699 390 403 571 323 613 186 101 708 131 221 940 913 121\n",
      " 476  35 396 494 815 787 757  47 505  51]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "training_idx =row_indices[:(row_indices.shape[0]*60)//100]\n",
    "crossVal_idx = row_indices[(row_indices.shape[0]*60)//100:(row_indices.shape[0]*80)//100]\n",
    "test_idx = row_indices[(row_indices.shape[0]*80)//100:row_indices.shape[0]]\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[training_idx,:]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[crossVal_idx,:]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[test_idx,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
